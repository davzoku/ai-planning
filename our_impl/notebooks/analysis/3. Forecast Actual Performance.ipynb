{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "\n",
    "sales_dir = '../assets/processed_sales.csv'\n",
    "cal_dir = '../assets/calendar_week.csv'\n",
    "events_dir = '../assets/events.csv'\n",
    "zscore_dir = '../assets/Z_scores.csv'\n",
    "dd_coeff_dir = '../assets/Coefficients.csv'\n",
    "prices_dir = '../assets/prices.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_demand_sensitive(ga_output: pd.DataFrame, sku_list: list, start: float, period: int) -> float:\n",
    "    global sales, cal_week, events, zscore, all_skus\n",
    "\n",
    "    histr = start - 1\n",
    "    end =  start + period\n",
    "\n",
    "    idx_frame = [(SKU, Time_ID) for SKU in sku_list for Time_ID in range(start, end)]\n",
    "    idx_frame = pd.DataFrame(idx_frame, columns=['SKU', 'Time_ID'])\n",
    "\n",
    "    sales_hist = sales[(sales['SKU'].isin(sku_list)) & (sales['Time_ID']>=histr-period-5) & (sales['Time_ID']<=histr)].copy()\n",
    "\n",
    "    ## Preapare GA dataframe\n",
    "    ga_df = ga_output.copy()\n",
    "\n",
    "    ## Create Competitor Matrix\n",
    "    comp_matrix_columns = [f'{sku}_{promo}' for sku in all_skus for promo in ['Discount', 'Display', 'Feature', 'Sales']]\n",
    "    comp_matrix = pd.DataFrame(columns=comp_matrix_columns, index=range(len(sku_list)*period))\n",
    "    comp_matrix = pd.concat([idx_frame, comp_matrix], axis=1)\n",
    "    for sku in sku_list:\n",
    "        for promo in ['Discount', 'Display', 'Feature']:\n",
    "            neg = 1 #-1 if promo in ['Display', 'Feature'] else 1\n",
    "            tmp = list(ga_df[ga_df['SKU']==sku][promo] * neg) * period\n",
    "            tmp = pd.DataFrame(tmp)\n",
    "            comp_matrix[sku + \"_\" + promo] = tmp\n",
    "            comp_matrix.loc[comp_matrix['SKU'] == sku, [sku + \"_\" + promo]] = 0\n",
    "    comp_matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # comp_matrix.head()\n",
    "\n",
    "\n",
    "    revenue = []\n",
    "\n",
    "    ## Iterate through each week through the demand function\n",
    "    ## Obtain sales prediction and feed back into historical sales for picking\\\n",
    "    for week in range(start, end):\n",
    "\n",
    "        dd_coeff_val = dd_coeff[sku_list].values\n",
    "        year = time_year[time_year[\"Time_ID\"] == week][\"Year\"].values[0]\n",
    "        ga_tmp = ga_df[ga_df[\"Time_ID\"] == week].copy()\n",
    "        for promo in [\"Discount\", \"Feature\", \"Display\"]:\n",
    "            merge = sales_hist[sales_hist[\"Time_ID\"] == week - 1][\n",
    "                [\"SKU\", promo]\n",
    "            ].copy()\n",
    "            merge = merge.rename(columns={promo: promo + \"lag\"})\n",
    "            ga_tmp = pd.merge(ga_tmp, merge, on=[\"SKU\"], how=\"left\")\n",
    "\n",
    "        ### CHANGE Log_sls to Sales\n",
    "        merge = sales_hist[sales_hist[\"Time_ID\"] == week - 1][\n",
    "            [\"SKU\", \"Sales\", \"Lag8w_avg_sls\"]\n",
    "        ].copy()\n",
    "        merge = merge.rename(\n",
    "            columns={\"Sales\": \"Saleslag\", \"Lag8w_avg_sls\": \"Sales_mov_avg\"}\n",
    "        )\n",
    "        ga_tmp = pd.merge(ga_tmp, merge, on=[\"SKU\"], how=\"left\")\n",
    "\n",
    "        events_tmp = (\n",
    "            events[events[\"Time_ID\"] == week]\n",
    "            .drop(columns=\"Time_ID\")\n",
    "            .copy()\n",
    "        )\n",
    "        events_tmp = pd.concat([events_tmp] * len(sku_list), ignore_index=True)\n",
    "        ga_tmp = pd.concat([ga_tmp, events_tmp], axis=1)\n",
    "\n",
    "        comp_tmp = (\n",
    "            comp_matrix[comp_matrix[\"Time_ID\"] == week]\n",
    "            .drop(columns=\"Time_ID\")\n",
    "            .copy()\n",
    "        )\n",
    "        for sku in sku_list:\n",
    "            tmp = sales_hist[\n",
    "                (sales_hist[\"SKU\"] == sku) & (sales_hist[\"Time_ID\"] == week - 1)\n",
    "            ][\"Sales\"].item()\n",
    "            comp_tmp[sku + \"_Sales\"] = tmp\n",
    "            comp_tmp.loc[comp_tmp[\"SKU\"] == sku, [sku + \"_Sales\"]] = 0\n",
    "\n",
    "        ga_tmp = pd.merge(ga_tmp, comp_tmp, on=[\"SKU\"], how=\"left\")\n",
    "\n",
    "        ga_val = ga_tmp.drop(columns=[\"SKU\", \"Time_ID\"]).values\n",
    "\n",
    "        sales_output = np.diag(ga_val.dot(dd_coeff_val))\n",
    "\n",
    "        ### ADD MODEL BIAS\n",
    "        bias_tmp = dd_bias[dd_bias[\"SKU\"].isin(sku_list)][\"bias\"].values\n",
    "        sales_output = sales_output + bias_tmp\n",
    "        sales_output[sales_output < 0] = 0\n",
    "\n",
    "        prices_tmp = prices[\n",
    "            (prices[\"SKU\"].isin(sku_list)) & (prices[\"Year\"] == year)\n",
    "        ][\"med_price\"].values\n",
    "\n",
    "        discounts_tmp = 2 - (ga_tmp['Discount'].values * zscore_tmp['Std_deviation'].values + zscore_tmp['Mean'].values)\n",
    "        other_costs_tmp = ga_tmp['Feature'].values * 5 + ga_tmp['Display'].values * 10\n",
    "\n",
    "        revenue.append(sum(sales_output * prices_tmp * discounts_tmp - other_costs_tmp))\n",
    "\n",
    "        ## Prep for historical insert\n",
    "        prep_tmp = sales_hist[sales_hist[\"Time_ID\"] == week - 1][\n",
    "            [\"SKU\", \"Lag7w_sum_sls\"]\n",
    "        ].copy()\n",
    "        hist_prep = sales_hist[sales_hist[\"Time_ID\"] == week - 7][[\"SKU\", \"Sales\"]]\n",
    "        hist_prep = hist_prep.rename(columns={\"Sales\": \"Lag7w_sls\"})\n",
    "        hist_prep = pd.merge(hist_prep, prep_tmp, on=[\"SKU\"], how=\"left\")\n",
    "        hist_prep = hist_prep.drop(columns=[\"SKU\"])\n",
    "\n",
    "        ## Build historical insert\n",
    "        hist_insert = ga_tmp[[\"SKU\", \"Time_ID\", \"Discount\", \"Display\", \"Feature\"]]\n",
    "        hist_insert[\"Year\"] = year\n",
    "        hist_insert[\"Sales\"] = sales_output\n",
    "        # hist_insert[\"Log_sls\"] = -np.log(hist_insert[\"Sales\"]) ## NOT USED ANYMORE\n",
    "        hist_insert = pd.concat([hist_insert, hist_prep], axis=1)\n",
    "        hist_insert[\"Lag8w_avg_sls\"] = (\n",
    "            hist_insert[\"Lag7w_sum_sls\"] + hist_insert[\"Sales\"]\n",
    "        ) / 8\n",
    "        hist_insert[\"Lag7w_sum_sls_upd\"] = (\n",
    "            hist_insert[\"Lag7w_sum_sls\"]\n",
    "            - hist_insert[\"Lag7w_sls\"]\n",
    "            + hist_insert[\"Sales\"]\n",
    "        )\n",
    "        hist_insert = hist_insert[\n",
    "            [\n",
    "                \"SKU\",\n",
    "                \"Time_ID\",\n",
    "                \"Year\",\n",
    "                \"Sales\",\n",
    "                \"Discount\",\n",
    "                \"Display\",\n",
    "                \"Feature\",\n",
    "                # \"Log_sls\",  ## NOT USED ANYMORE\n",
    "                \"Lag8w_avg_sls\",\n",
    "                \"Lag7w_sum_sls_upd\",\n",
    "            ]\n",
    "        ]\n",
    "        hist_insert = hist_insert.rename(\n",
    "            columns={\"Lag7w_sum_sls_upd\": \"Lag7w_sum_sls\"}\n",
    "        )\n",
    "        hist_insert.fillna(0, inplace=True)\n",
    "\n",
    "        ## Insert results into historical\n",
    "        sales_hist = pd.concat([sales_hist, hist_insert], ignore_index=True)\n",
    "\n",
    "        # print(sales_output)\n",
    "\n",
    "    return sum(revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forecasted Actual Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast Actual: 80149.33991616753\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sales = pd.read_csv(sales_dir)\n",
    "cal_week = pd.read_csv(cal_dir)\n",
    "events = pd.read_csv(events_dir)\n",
    "zscore = pd.read_csv(zscore_dir)\n",
    "dd_coeff = pd.read_csv(dd_coeff_dir).drop(columns='Unnamed: 0')\n",
    "prices = pd.read_csv(prices_dir)\n",
    "\n",
    "all_skus = sorted(sales['SKU'].unique())\n",
    "\n",
    "time_year = sales[['Time_ID', 'Year']].copy()\n",
    "time_year = time_year.drop_duplicates()\n",
    "zscore_tmp= pd.read_csv(zscore_dir)\n",
    "zscore_tmp = zscore_tmp.rename(columns={'Unnamed: 0': 'SKU'})\n",
    "zscore_tmp = zscore_tmp.sort_values(by='SKU')\n",
    "zscore = zscore_tmp[['SKU', 'Mean', 'Std_deviation']]\n",
    "dd_bias = zscore_tmp[['SKU', 'bias']]\n",
    "\n",
    "sku_list = all_skus\n",
    "start = 1376\n",
    "period = 8\n",
    "\n",
    "\n",
    "df_full = pd.read_csv(\"../assets/processed_sales.csv\")\n",
    " \n",
    "df_filtered = df_full[(df_full['Time_ID'] >= start) & (df_full['Time_ID'] <= start + period)]\n",
    "df_filtered = df_filtered[df_filtered['SKU'].isin(sku_list)]\n",
    "df_filtered = df_filtered.sort_values(by = ['Time_ID', 'SKU'], ascending = [True, True])\n",
    "df_filtered = df_filtered[['SKU', 'Time_ID', 'Discount', 'Feature', 'Display']]\n",
    "\n",
    "revenue = fitness_demand_sensitive(df_filtered, sku_list, start, period)\n",
    "cost = df_filtered[['Display', 'Feature']].sum().sum() * 20\n",
    "\n",
    "print(f'Forecast Actual: {revenue}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actual Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Revenue: 80213.26306342347\n",
      "Average Weekly Features: 4.875\n",
      "Average Weekly Display: 0.0\n",
      "Average Weekly Discount: 18.75\n",
      "Average Weekly Discount Amount: 0.35073869212754794\n"
     ]
    }
   ],
   "source": [
    "# Selecct data within period\n",
    "df_actual = df_full[(df_full['Time_ID'] >= start) & (df_full['Time_ID'] <= start + period -1)]\n",
    "df_actual = df_actual[df_actual['SKU'].isin(sku_list)]\n",
    "\n",
    "# Get price from processed data\n",
    "df_price = pd.read_csv(\"../assets/combined_milk_final.csv\")\n",
    "df_price = df_price[df_price['Store_ID'] == 236117]\n",
    "prices_filtered = df_price[['Time_ID','SKU', 'Sales', 'Price']]\n",
    "df_actual = df_actual[['SKU', 'Time_ID', 'Discount', 'Feature', 'Display']]\n",
    "df_actual = df_actual.merge(prices_filtered, on = ['Time_ID', 'SKU'])\n",
    "df_actual = df_actual.merge(zscore, on = 'SKU')\n",
    "df_actual['Discount_updated'] = df_actual['Discount'] * df_actual['Std_deviation'] + df_actual['Mean'] - 1\n",
    "\n",
    "df_actual['Revenue'] = df_actual['Sales']*df_actual['Price']\n",
    "\n",
    "# Calculate promotion metrics\n",
    "avg_weekly_feature = df_actual.groupby(['Time_ID'])['Feature'].sum().mean()\n",
    "avg_weekly_display = df_actual.groupby(['Time_ID'])['Display'].sum().mean()\n",
    "\n",
    "avg_weekly_discount = df_actual[df_actual['Discount_updated'] > 0].groupby('Time_ID').size().mean()\n",
    "avg_discount_values = df_actual[df_actual['Discount_updated'] > 0].groupby('Time_ID')['Discount'].mean().mean()\n",
    "\n",
    "revenue = sum(df_actual['Revenue'])\n",
    "\n",
    "print(f'Actual Revenue: {revenue}')\n",
    "print(f\"Average Weekly Features: {avg_weekly_feature}\")\n",
    "print(f\"Average Weekly Display: {avg_weekly_display}\")\n",
    "print(f\"Average Weekly Discount: {avg_weekly_discount}\")\n",
    "print(f\"Average Weekly Discount Amount: {avg_discount_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
